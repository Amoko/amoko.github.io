# CNN Note

卷积神经网络（Convolutional Neural Networks），深度学习大佬![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/33px-Flag_of_France.svg.png)法国人 Yann LeCun 的大作，在图像识别领域具有统治级的优秀表现。CNN与普通神经网络的区别在于两个定制的隐层结构，卷积层和池化层。



### 卷积层（Convolution Layer）

在卷积层，一个神经元的权值就是一个卷积核的参数。卷积核本质是一个滤波（filter），因为以一个卷积核对整个图像的不同部分进行扫描，因此说图像的不同部分之间是**权值共享**的。再加上ReLU等非线性激活函数来达到提取图像高维特征的目的。



以下以 Stanford CS231n中的例子来说明卷积层的计算过程：

![](img/conv.PNG)

输入为$5\times5\times3$的RBG三通道图像矩阵$x$。卷积层2个神经元的卷积核为$w_0$和$w_1$，两个$3\times3\times3$的滤波矩阵。（卷积核最后一个维度值和输入图片通道数相等，相当于给每个通道$5\times5$的图片，配一个$3\times3$的滤波。）

将3个通道的卷积值求和，即是对应位置的输出结果。



对图像进行扫描需要额外定义的两个参数：

padding，边缘填充，在原始图像边缘填充的个数。

stride，卷积核在原始图像上扫描时的步长，即移动的位数。



总结：

输入图像为$W_1\times H_1\times D_1$；

定义卷积层神经元个数为$K$，每个神经元卷积核尺寸为$F\times F\times D_1$，填充位数padding为$P$，步长stride为$S$；

则此卷积层的输出维度为$W_2*H_2*K$，其中$W_2=(W_1-F+2P)/S+1$，是$H_2=(H_1-F+2P)/S+1$。

在上例中，输入数据$W_1=H_1=5,D_1=3$。，卷积层$K=2,F=3,P=1,S=2$，则最终的输出结果$W_2=H_2=(5-3+2\times1)/2+1=3$。



###  池化层（Pooling Layer）

池化层的作用是降维，提升CNN的泛化能力。

池化的方式有很多，常用的是 max pooling，即选择区域内最大的元素值作为对应位置的输出。

![](img/pool.PNG)



### Reference

\[1] 李航 (2012) 统计学习方法. 清华大学出版社, 北京.


\[2] [CS231n: CNN for Visual Recognition ](http://cs231n.github.io/convolutional-networks/)
