---
title: CNN Notes
layout: default
tags: [machine learning,]
---



# CNN Notes

卷积神经网络（Convolutional Neural Networks），深度学习大佬![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/33px-Flag_of_France.svg.png)法国人 Yann LeCun 的大作，在图像识别领域具有统治级的优秀表现。CNN与普通神经网络的区别在于两个定制的隐层结构，卷积层和池化层。



### 卷积层（Convolution Layer）

在卷积层，一个神经元的权值就是一个卷积核的参数。卷积核本质是一个滤波（filter），因为以一个卷积核对整个图像的不同部分进行扫描，因此说图像的不同部分之间是**权值共享**的。再加上ReLU等非线性激活函数来达到提取图像高维特征的目的。



以下以 Stanford CS231n中的例子来说明卷积层的计算过程：

![](/img/conv.PNG)

输入为$5\times5\times3$的RBG三通道图像矩阵$x$。卷积层有两个神经元，其卷积核分别为$w_0$和$w_1$，都是$3\times3\times3$的滤波矩阵。（卷积核最后一个维度值和输入图片通道数相等，相当于给每个通道$5\times5$的图片，配一个$3\times3$的滤波。）

对卷积核$w_0$来说，此神经元对应位置的输出值是3个输入信道的卷积值之和。

对图像进行扫描需要额外定义的两个参数：

- padding，边缘填充，在原始图像边缘填充的个数。
- stride，卷积核在原始图像上扫描时的步长，即移动的位数。



总结：

输入图像为$W_1\times H_1\times D_1$；

定义卷积层神经元个数为$K​$，每个神经元卷积核尺寸为$F\times F\times D_1​$，填充位数padding为$P​$，步长stride为$S​$；

则此卷积层的输出维度为$W_2\times H_2\times K$，其中$W_2=(W_1-F+2P)/S+1$，是$H_2=(H_1-F+2P)/S+1$。

上例中，输入数据$W_1=H_1=5,D_1=3$，卷积层$K=2,F=3,P=1,S=2$，则最终的输出结果$W_2=H_2=(5-3+2\times1)/2+1=3$。



#### PyTorch中的卷积层

``` python
class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
```

以上是PyTorch中一个2D的卷积层定义，必须指定的参数有三个：in_channels, out_channels, kernel_size。

- in_channels，输入信道，上一层神经元的个数。若为第一层，则对于RGB三通道图像数据，这个值为3。

- out_channels，输出信道，此卷积层神经元的个数，即卷积核的数目。

- kernel_size，卷积核尺寸。



###  池化层（Pooling Layer）

池化层的作用是降维，提升CNN的泛化能力。

池化的方式有很多，常用的是 max pooling，即选择区域内最大的元素值作为对应位置的输出。

![](/img/pool.PNG)

#### PyTorch中的池化层

```python
class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
```

以上是PyTorch中一个2D的池化层定义，必须指定的参数有两个： kernel_size, stride。

- kernel_size，卷积核尺寸。
- kernel_size，步长。



### Demo in PyTorch

下段代码定义了一个拥有3个卷积层、3个全连接层，总深度为6的神经网络。

数据为$32\times32$的三通道图像，即输入维度$3\times32\times32$；多分类标签有10个，即输出维度为10。

我们需要计算最后一层卷积层的输出维度$C\times H\times W$，来给全连接层的输入维度赋值，以下为此维度的计算过程。

- Step1，第1层卷积神经元个数为6，卷积核为$3\times3$，则此层输出维度为$6\times30\times30$；
- Step2，第2层卷积神经元个数为12，卷积核为$3\times3$，则此层输出维度为$12\times28\times28$；
- Step3，池化层池化核为$2\times2$，步长为2，则此层输出维度为$12\times14\times14$；
- Step4，第3层卷积神经元个数为24，卷积核为$3\times3$，则此层输出维度为$24\times12\times12$；
- Step5，池化层池化核为$2\times2$，步长为2，则此层输出维度为$24\times6\times6$。

``` python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.pool = nn.MaxPool2d(2, 2)
        self.conv1 = nn.Conv2d(3, 6, 3)
        self.conv2 = nn.Conv2d(6, 12, 3)
        self.conv3 = nn.Conv2d(12, 24, 3)
        # C*H*W
        self.fc1 = nn.Linear(24 * 6 * 6, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # 1-2
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        # 3
        x = F.relu(self.conv3(x))
        x = self.pool(x)
        # reshape
        x = x.view(-1, 24 * 6 * 6)
        # fully connected        
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
```



### Reference

\[1] 李航 (2012) 统计学习方法. 清华大学出版社, 北京.


\[2] [CS231n: CNN for Visual Recognition ](http://cs231n.github.io/convolutional-networks/)
