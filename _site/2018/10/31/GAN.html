<!DOCTYPE html>
<html lang="en-US">

<head>

    <meta charset="UTF-8">
    <link rel="icon" type="image/png"  href="/img/favicon.jinja.png">
<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>GAN Notes | Yonji’s Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="GAN Notes" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1 GAN是什么？ Generative adversarial nets，生成对抗式网络，Ian Goodfellowイアン・グッドフェロー 2014年提出的模型。 简单来讲就是定义两个神经网络模型，一个是验钞机、一个假币生成机，以对抗博弈的方式来彼此学习进步，最终达到生命的大和谐（误）。 基础架构 $r$：真实数据； $z$：随机噪声，服从分布$p_z(z)$； $G(z)$：生成器，用神经网络去生成仿造数据； $D(x)$：判别器，判定$x$来自真实数据的概率。 最终目标 $G(z)$ 学到的分布和真实数据分布相同，$p_g=p_r$，让 $D(x)$ 无法区分 $G(z)$ 与真实数据，即 $D(x)=\frac{1}{2}$。 2 如何优化？ 2.1 GAN的优化目标 2.2 minimax算法 问题背景是零和博弈。 假设有A，B两个玩家，双方利益之和为零或一个常数，那么任一方的获利必然意味着对方的损失。 令A玩家得分为$V$，那么A玩家目标是最大化$V$。对于博弈问题，在A玩家做出最优解的同时，也要假设对手是有智商的，所以B玩家目标是最小化$V$。 Minimax算法就是在A的回合最大化$V$，在B的回合最小化$V$，以一定深度交替计算求出最优解。 所以GAN的优化目标，式$(1)$，也是分解为两个部分来进行。 2.3 两个子优化目标 1 判别器：最大化$D(x)$的正确分类率 2 生成器：最小化$D(x)$的正确分类率 3 PyTorch实现 实现代码基于莫烦的 GAN 教程，有改动。 $r​$：以介于一定范围的二次函数作为真实数据。$y=ax^2+a-1, a\sim U[1,3]​$，并从 $[-2,2]​$ 均匀取 DATA_COMPONENTS 个点，作为一个函数的抽样； $z$：$z\sim N[0,1]$，因为直接使用 torch.randn() 生成随机数，而这个函数使用标准正态分布（见文档）； $G(z)​$：两层神经网络； $D(x)$：两层神经网络。 完整代码如下： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Oct 30 20:00:14 2018 @author: Yonji &quot;&quot;&quot; import torch import torch.nn as nn import torch.nn.functional as F import numpy as np import matplotlib.pyplot as plt BATCH_SIZE = 64 LR_G, LR_D = 0.0001, 0.0001 # learning rate for G, D NOISE_COMPONENTS = 5 # G的输入维度、即噪声维度 DATA_COMPONENTS = 15 # G的输出维度、同时也是D的输入维度、即真实数据维度 # x轴坐标点、[-1, 1]之间等分、再复制batch_size个 PAINT_POINTS = np.array( [np.linspace(-2, 2, DATA_COMPONENTS) for _ in range(BATCH_SIZE)]) # real data def artist_works(): # lower &amp; upper bound a = np.random.uniform(1, 3, size=BATCH_SIZE)[:, np.newaxis] paintings = a * np.power(PAINT_POINTS, 2) + a - 1 paintings = torch.from_numpy(paintings).float() return paintings class GNet(nn.Module): def __init__(self): super(GNet, self).__init__() self.fc1 = nn.Linear(NOISE_COMPONENTS, 128) self.fc2 = nn.Linear(128, DATA_COMPONENTS) def forward(self, x): x = F.relu(self.fc1(x)) x = self.fc2(x) return x class DNet(nn.Module): def __init__(self): super(DNet, self).__init__() self.fc1 = nn.Linear(DATA_COMPONENTS, 128) self.fc2 = nn.Linear(128, 1) def forward(self, x): x = F.relu(self.fc1(x)) x = torch.sigmoid(self.fc2(x)) return x if __name__ == &quot;__main__&quot;: D, G = DNet(), GNet() opt_D = torch.optim.Adam(D.parameters(), lr=LR_D) opt_G = torch.optim.Adam(G.parameters(), lr=LR_G) plt.ion() for epoch in range(401): artist_paintings = artist_works() # real data G_ideas = torch.randn(BATCH_SIZE, NOISE_COMPONENTS) # z G_paintings = G(G_ideas) # G(z) # 论文公式、MLE loss prob_real = D(artist_paintings) prob_fake = D(G_paintings) D_loss = - torch.mean(torch.log(prob_real) + torch.log(1. - prob_fake)) G_loss = torch.mean(torch.log(1. - prob_fake)) # Loss BP、更新参数 opt_D.zero_grad() D_loss.backward(retain_graph=True) # reusing computational graph opt_D.step() opt_G.zero_grad() G_loss.backward() opt_G.step() # plotting if epoch % 100 == 0: plt.cla() plt.plot(PAINT_POINTS[0], 3 * np.power(PAINT_POINTS[0], 2) + 2, &quot;--&quot;, c=&#39;#000066&#39;, lw=2, label=&#39;upper bound of data&#39;) plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, &quot;--&quot;, c=&#39;#4AD631&#39;, lw=2, label=&#39;lower bound of data&#39;) plt.plot(PAINT_POINTS[0], artist_paintings.data.numpy()[0], c=&#39;#0066ff&#39;, lw=3, label=&#39;a real data&#39;) plt.plot(PAINT_POINTS[0], G_paintings.data.numpy()[0], c=&#39;red&#39;, lw=3, label=&#39;G(z)&#39;) plt.text(-1.2, 10, &#39;epoch = %d&#39; % epoch, fontdict={&#39;size&#39;: 14}) plt.text(-1.2, 9, &#39;D_accuracy = %.2f&#39; % prob_real.data.numpy().mean(), fontdict={&#39;size&#39;: 14}) plt.text(-1.2, 8, &#39;D_loss = %.2f&#39; % D_loss.data.numpy(), fontdict={&#39;size&#39;: 14}) plt.ylim((0, 14)) plt.legend(loc=&#39;upper right&#39;, fontsize=10) plt.draw();plt.pause(0.02) plt.ioff() plt.show() 结果如下图： 4 このディオだ！ WRYYYYYYYYYY！ Reference [1] MSRA 到底什么是生成式对抗网络GAN？ [2] 莫烦 GAN with Pytorch 教程" />
<meta property="og:description" content="1 GAN是什么？ Generative adversarial nets，生成对抗式网络，Ian Goodfellowイアン・グッドフェロー 2014年提出的模型。 简单来讲就是定义两个神经网络模型，一个是验钞机、一个假币生成机，以对抗博弈的方式来彼此学习进步，最终达到生命的大和谐（误）。 基础架构 $r$：真实数据； $z$：随机噪声，服从分布$p_z(z)$； $G(z)$：生成器，用神经网络去生成仿造数据； $D(x)$：判别器，判定$x$来自真实数据的概率。 最终目标 $G(z)$ 学到的分布和真实数据分布相同，$p_g=p_r$，让 $D(x)$ 无法区分 $G(z)$ 与真实数据，即 $D(x)=\frac{1}{2}$。 2 如何优化？ 2.1 GAN的优化目标 2.2 minimax算法 问题背景是零和博弈。 假设有A，B两个玩家，双方利益之和为零或一个常数，那么任一方的获利必然意味着对方的损失。 令A玩家得分为$V$，那么A玩家目标是最大化$V$。对于博弈问题，在A玩家做出最优解的同时，也要假设对手是有智商的，所以B玩家目标是最小化$V$。 Minimax算法就是在A的回合最大化$V$，在B的回合最小化$V$，以一定深度交替计算求出最优解。 所以GAN的优化目标，式$(1)$，也是分解为两个部分来进行。 2.3 两个子优化目标 1 判别器：最大化$D(x)$的正确分类率 2 生成器：最小化$D(x)$的正确分类率 3 PyTorch实现 实现代码基于莫烦的 GAN 教程，有改动。 $r​$：以介于一定范围的二次函数作为真实数据。$y=ax^2+a-1, a\sim U[1,3]​$，并从 $[-2,2]​$ 均匀取 DATA_COMPONENTS 个点，作为一个函数的抽样； $z$：$z\sim N[0,1]$，因为直接使用 torch.randn() 生成随机数，而这个函数使用标准正态分布（见文档）； $G(z)​$：两层神经网络； $D(x)$：两层神经网络。 完整代码如下： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Oct 30 20:00:14 2018 @author: Yonji &quot;&quot;&quot; import torch import torch.nn as nn import torch.nn.functional as F import numpy as np import matplotlib.pyplot as plt BATCH_SIZE = 64 LR_G, LR_D = 0.0001, 0.0001 # learning rate for G, D NOISE_COMPONENTS = 5 # G的输入维度、即噪声维度 DATA_COMPONENTS = 15 # G的输出维度、同时也是D的输入维度、即真实数据维度 # x轴坐标点、[-1, 1]之间等分、再复制batch_size个 PAINT_POINTS = np.array( [np.linspace(-2, 2, DATA_COMPONENTS) for _ in range(BATCH_SIZE)]) # real data def artist_works(): # lower &amp; upper bound a = np.random.uniform(1, 3, size=BATCH_SIZE)[:, np.newaxis] paintings = a * np.power(PAINT_POINTS, 2) + a - 1 paintings = torch.from_numpy(paintings).float() return paintings class GNet(nn.Module): def __init__(self): super(GNet, self).__init__() self.fc1 = nn.Linear(NOISE_COMPONENTS, 128) self.fc2 = nn.Linear(128, DATA_COMPONENTS) def forward(self, x): x = F.relu(self.fc1(x)) x = self.fc2(x) return x class DNet(nn.Module): def __init__(self): super(DNet, self).__init__() self.fc1 = nn.Linear(DATA_COMPONENTS, 128) self.fc2 = nn.Linear(128, 1) def forward(self, x): x = F.relu(self.fc1(x)) x = torch.sigmoid(self.fc2(x)) return x if __name__ == &quot;__main__&quot;: D, G = DNet(), GNet() opt_D = torch.optim.Adam(D.parameters(), lr=LR_D) opt_G = torch.optim.Adam(G.parameters(), lr=LR_G) plt.ion() for epoch in range(401): artist_paintings = artist_works() # real data G_ideas = torch.randn(BATCH_SIZE, NOISE_COMPONENTS) # z G_paintings = G(G_ideas) # G(z) # 论文公式、MLE loss prob_real = D(artist_paintings) prob_fake = D(G_paintings) D_loss = - torch.mean(torch.log(prob_real) + torch.log(1. - prob_fake)) G_loss = torch.mean(torch.log(1. - prob_fake)) # Loss BP、更新参数 opt_D.zero_grad() D_loss.backward(retain_graph=True) # reusing computational graph opt_D.step() opt_G.zero_grad() G_loss.backward() opt_G.step() # plotting if epoch % 100 == 0: plt.cla() plt.plot(PAINT_POINTS[0], 3 * np.power(PAINT_POINTS[0], 2) + 2, &quot;--&quot;, c=&#39;#000066&#39;, lw=2, label=&#39;upper bound of data&#39;) plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, &quot;--&quot;, c=&#39;#4AD631&#39;, lw=2, label=&#39;lower bound of data&#39;) plt.plot(PAINT_POINTS[0], artist_paintings.data.numpy()[0], c=&#39;#0066ff&#39;, lw=3, label=&#39;a real data&#39;) plt.plot(PAINT_POINTS[0], G_paintings.data.numpy()[0], c=&#39;red&#39;, lw=3, label=&#39;G(z)&#39;) plt.text(-1.2, 10, &#39;epoch = %d&#39; % epoch, fontdict={&#39;size&#39;: 14}) plt.text(-1.2, 9, &#39;D_accuracy = %.2f&#39; % prob_real.data.numpy().mean(), fontdict={&#39;size&#39;: 14}) plt.text(-1.2, 8, &#39;D_loss = %.2f&#39; % D_loss.data.numpy(), fontdict={&#39;size&#39;: 14}) plt.ylim((0, 14)) plt.legend(loc=&#39;upper right&#39;, fontsize=10) plt.draw();plt.pause(0.02) plt.ioff() plt.show() 结果如下图： 4 このディオだ！ WRYYYYYYYYYY！ Reference [1] MSRA 到底什么是生成式对抗网络GAN？ [2] 莫烦 GAN with Pytorch 教程" />
<link rel="canonical" href="http://localhost:4000/2018/10/31/GAN.html" />
<meta property="og:url" content="http://localhost:4000/2018/10/31/GAN.html" />
<meta property="og:site_name" content="Yonji’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-31T00:00:00-07:00" />
<script type="application/ld+json">
{"description":"1 GAN是什么？ Generative adversarial nets，生成对抗式网络，Ian Goodfellowイアン・グッドフェロー 2014年提出的模型。 简单来讲就是定义两个神经网络模型，一个是验钞机、一个假币生成机，以对抗博弈的方式来彼此学习进步，最终达到生命的大和谐（误）。 基础架构 $r$：真实数据； $z$：随机噪声，服从分布$p_z(z)$； $G(z)$：生成器，用神经网络去生成仿造数据； $D(x)$：判别器，判定$x$来自真实数据的概率。 最终目标 $G(z)$ 学到的分布和真实数据分布相同，$p_g=p_r$，让 $D(x)$ 无法区分 $G(z)$ 与真实数据，即 $D(x)=\\frac{1}{2}$。 2 如何优化？ 2.1 GAN的优化目标 2.2 minimax算法 问题背景是零和博弈。 假设有A，B两个玩家，双方利益之和为零或一个常数，那么任一方的获利必然意味着对方的损失。 令A玩家得分为$V$，那么A玩家目标是最大化$V$。对于博弈问题，在A玩家做出最优解的同时，也要假设对手是有智商的，所以B玩家目标是最小化$V$。 Minimax算法就是在A的回合最大化$V$，在B的回合最小化$V$，以一定深度交替计算求出最优解。 所以GAN的优化目标，式$(1)$，也是分解为两个部分来进行。 2.3 两个子优化目标 1 判别器：最大化$D(x)$的正确分类率 2 生成器：最小化$D(x)$的正确分类率 3 PyTorch实现 实现代码基于莫烦的 GAN 教程，有改动。 $r​$：以介于一定范围的二次函数作为真实数据。$y=ax^2+a-1, a\\sim U[1,3]​$，并从 $[-2,2]​$ 均匀取 DATA_COMPONENTS 个点，作为一个函数的抽样； $z$：$z\\sim N[0,1]$，因为直接使用 torch.randn() 生成随机数，而这个函数使用标准正态分布（见文档）； $G(z)​$：两层神经网络； $D(x)$：两层神经网络。 完整代码如下： # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Oct 30 20:00:14 2018 @author: Yonji &quot;&quot;&quot; import torch import torch.nn as nn import torch.nn.functional as F import numpy as np import matplotlib.pyplot as plt BATCH_SIZE = 64 LR_G, LR_D = 0.0001, 0.0001 # learning rate for G, D NOISE_COMPONENTS = 5 # G的输入维度、即噪声维度 DATA_COMPONENTS = 15 # G的输出维度、同时也是D的输入维度、即真实数据维度 # x轴坐标点、[-1, 1]之间等分、再复制batch_size个 PAINT_POINTS = np.array( [np.linspace(-2, 2, DATA_COMPONENTS) for _ in range(BATCH_SIZE)]) # real data def artist_works(): # lower &amp; upper bound a = np.random.uniform(1, 3, size=BATCH_SIZE)[:, np.newaxis] paintings = a * np.power(PAINT_POINTS, 2) + a - 1 paintings = torch.from_numpy(paintings).float() return paintings class GNet(nn.Module): def __init__(self): super(GNet, self).__init__() self.fc1 = nn.Linear(NOISE_COMPONENTS, 128) self.fc2 = nn.Linear(128, DATA_COMPONENTS) def forward(self, x): x = F.relu(self.fc1(x)) x = self.fc2(x) return x class DNet(nn.Module): def __init__(self): super(DNet, self).__init__() self.fc1 = nn.Linear(DATA_COMPONENTS, 128) self.fc2 = nn.Linear(128, 1) def forward(self, x): x = F.relu(self.fc1(x)) x = torch.sigmoid(self.fc2(x)) return x if __name__ == &quot;__main__&quot;: D, G = DNet(), GNet() opt_D = torch.optim.Adam(D.parameters(), lr=LR_D) opt_G = torch.optim.Adam(G.parameters(), lr=LR_G) plt.ion() for epoch in range(401): artist_paintings = artist_works() # real data G_ideas = torch.randn(BATCH_SIZE, NOISE_COMPONENTS) # z G_paintings = G(G_ideas) # G(z) # 论文公式、MLE loss prob_real = D(artist_paintings) prob_fake = D(G_paintings) D_loss = - torch.mean(torch.log(prob_real) + torch.log(1. - prob_fake)) G_loss = torch.mean(torch.log(1. - prob_fake)) # Loss BP、更新参数 opt_D.zero_grad() D_loss.backward(retain_graph=True) # reusing computational graph opt_D.step() opt_G.zero_grad() G_loss.backward() opt_G.step() # plotting if epoch % 100 == 0: plt.cla() plt.plot(PAINT_POINTS[0], 3 * np.power(PAINT_POINTS[0], 2) + 2, &quot;--&quot;, c=&#39;#000066&#39;, lw=2, label=&#39;upper bound of data&#39;) plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, &quot;--&quot;, c=&#39;#4AD631&#39;, lw=2, label=&#39;lower bound of data&#39;) plt.plot(PAINT_POINTS[0], artist_paintings.data.numpy()[0], c=&#39;#0066ff&#39;, lw=3, label=&#39;a real data&#39;) plt.plot(PAINT_POINTS[0], G_paintings.data.numpy()[0], c=&#39;red&#39;, lw=3, label=&#39;G(z)&#39;) plt.text(-1.2, 10, &#39;epoch = %d&#39; % epoch, fontdict={&#39;size&#39;: 14}) plt.text(-1.2, 9, &#39;D_accuracy = %.2f&#39; % prob_real.data.numpy().mean(), fontdict={&#39;size&#39;: 14}) plt.text(-1.2, 8, &#39;D_loss = %.2f&#39; % D_loss.data.numpy(), fontdict={&#39;size&#39;: 14}) plt.ylim((0, 14)) plt.legend(loc=&#39;upper right&#39;, fontsize=10) plt.draw();plt.pause(0.02) plt.ioff() plt.show() 结果如下图： 4 このディオだ！ WRYYYYYYYYYY！ Reference [1] MSRA 到底什么是生成式对抗网络GAN？ [2] 莫烦 GAN with Pytorch 教程","@type":"BlogPosting","url":"http://localhost:4000/2018/10/31/GAN.html","headline":"GAN Notes","dateModified":"2018-10-31T00:00:00-07:00","datePublished":"2018-10-31T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/10/31/GAN.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=b0ca346b5b38b55e1001eb0920382c9d2e5aa454">

  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
</head>


  <body>
    <section class="page-header">
      <h1 class="project-name">Yonji's Blog|
      <a href="http://localhost:4000">Home</a></h1>
      <!--
      <h2 class="project-tagline">OMG! They killed Kenny!</h2>
      -->
      <a href="https://github.com/Amoko/amoko.github.io" class="btn">View on GitHub</a>
    
      
    </section>

    <section class="main-content">
      <h2 id="1-gan是什么">1 GAN是什么？</h2>

<p>Generative adversarial nets，生成对抗式网络，<ruby>Ian Goodfellow<rt>イアン・グッドフェロー</rt></ruby> 2014年提出的模型。</p>

<p>简单来讲就是定义两个神经网络模型，一个是验钞机、一个假币生成机，以对抗博弈的方式来彼此学习进步，最终达到生命的大和谐（误）。</p>

<p><strong>基础架构</strong></p>

<p>$r$：真实数据；</p>

<p>$z$：随机噪声，服从分布$p_z(z)$；</p>

<p>$G(z)$：生成器，用神经网络去生成仿造数据；</p>

<p>$D(x)$：判别器，判定$x$来自真实数据的概率。</p>

<p><strong>最终目标</strong></p>

<p>$G(z)$ 学到的分布和真实数据分布相同，$p_g=p_r$，让 $D(x)$ 无法区分 $G(z)$ 与真实数据，即 $D(x)=\frac{1}{2}$。</p>

<h2 id="2-如何优化">2 如何优化？</h2>

<h3 id="21-gan的优化目标">2.1 GAN的优化目标</h3>

<p><script type="math/tex">\min_G \max_DV(D,G)=E_{x\sim p_r}[\log D(x)]+E_{x\sim p_g}[\log(1-D(x)]\tag{1}</script></p>
<h3 id="22-minimax算法">2.2 minimax算法</h3>

<p>问题背景是零和博弈。</p>

<p>假设有A，B两个玩家，双方利益之和为零或一个常数，那么任一方的获利必然意味着对方的损失。</p>

<p>令A玩家得分为$V$，那么A玩家目标是最大化$V$。对于博弈问题，在A玩家做出最优解的同时，也要假设对手是有智商的，所以B玩家目标是最小化$V$。</p>

<script type="math/tex; mode=display">\min_B \max_A V</script>

<p>Minimax算法就是在A的回合最大化$V$，在B的回合最小化$V$，以一定深度交替计算求出最优解。</p>

<p>所以GAN的优化目标，式$(1)$，也是分解为两个部分来进行。</p>

<h3 id="23-两个子优化目标">2.3 两个子优化目标</h3>

<p>1 判别器：最大化$D(x)$的正确分类率
<script type="math/tex">\max_D V(D,G)=E_{x\sim p_r}[\log D(x)]+E_{x\sim p_g}[\log(1-D(x)]\tag{2}</script>
2 生成器：最小化$D(x)$的正确分类率
<script type="math/tex">% <![CDATA[
\begin{aligned}
\min_G V(D,G)&= E_{x\sim p_g}[\log(1-D(x)]\\
&= E_{z\sim p_z(z)}[\log(1-D(G(z))]
\end{aligned}\tag{3} %]]></script></p>

<h2 id="3-pytorch实现">3 PyTorch实现</h2>

<blockquote>
  <p><em>实现代码基于莫烦的 GAN 教程，有改动。</em></p>
</blockquote>

<p>$r​$：以介于一定范围的二次函数作为真实数据。$y=ax^2+a-1, a\sim U[1,3]​$，并从 $[-2,2]​$ 均匀取 DATA_COMPONENTS 个点，作为一个函数的抽样；</p>

<p>$z$：$z\sim N[0,1]$，因为直接使用 torch.randn() 生成随机数，而这个函数使用标准正态分布（<a href="https://pytorch.org/docs/stable/torch.html#torch.randn">见文档</a>）；</p>

<p>$G(z)​$：两层神经网络；</p>

<p>$D(x)$：两层神经网络。</p>

<p>完整代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># -*- coding: utf-8 -*-</span>
<span class="s">"""
Created on Tue Oct 30 20:00:14 2018
@author: Yonji
"""</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">LR_G</span><span class="p">,</span> <span class="n">LR_D</span>  <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.0001</span> <span class="c"># learning rate for G, D</span>
<span class="n">NOISE_COMPONENTS</span> <span class="o">=</span> <span class="mi">5</span>         <span class="c"># G的输入维度、即噪声维度</span>
<span class="n">DATA_COMPONENTS</span> <span class="o">=</span> <span class="mi">15</span>         <span class="c"># G的输出维度、同时也是D的输入维度、即真实数据维度</span>

<span class="c"># x轴坐标点、[-1, 1]之间等分、再复制batch_size个</span>
<span class="n">PAINT_POINTS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">DATA_COMPONENTS</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)])</span>

<span class="c"># real data</span>
<span class="k">def</span> <span class="nf">artist_works</span><span class="p">():</span>
    <span class="c"># lower &amp; upper bound</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">paintings</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">paintings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">paintings</span><span class="p">)</span><span class="o">.</span><span class="nb">float</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">paintings</span>

<span class="k">class</span> <span class="nc">GNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">NOISE_COMPONENTS</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">DATA_COMPONENTS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">DNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">DATA_COMPONENTS</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">D</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">DNet</span><span class="p">(),</span> <span class="n">GNet</span><span class="p">()</span>
    <span class="n">opt_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR_D</span><span class="p">)</span>
    <span class="n">opt_G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR_G</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">401</span><span class="p">):</span>
        <span class="n">artist_paintings</span> <span class="o">=</span> <span class="n">artist_works</span><span class="p">()</span>                   <span class="c"># real data</span>
        <span class="n">G_ideas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NOISE_COMPONENTS</span><span class="p">)</span> <span class="c"># z</span>
        <span class="n">G_paintings</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">G_ideas</span><span class="p">)</span>                            <span class="c"># G(z)</span>
    
        <span class="c"># 论文公式、MLE loss</span>
        <span class="n">prob_real</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">artist_paintings</span><span class="p">)</span>
        <span class="n">prob_fake</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">G_paintings</span><span class="p">)</span>
        <span class="n">D_loss</span> <span class="o">=</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob_real</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">prob_fake</span><span class="p">))</span>
        <span class="n">G_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">prob_fake</span><span class="p">))</span>
        
        <span class="c"># Loss BP、更新参数 </span>
        <span class="n">opt_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">D_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>      <span class="c"># reusing computational graph</span>
        <span class="n">opt_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
        <span class="n">opt_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">G_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c"># plotting</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="s">"--"</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'#000066'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'upper bound of data'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">0</span><span class="p">,</span>
                     <span class="s">"--"</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'#4AD631'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'lower bound of data'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">artist_paintings</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
                     <span class="n">c</span><span class="o">=</span><span class="s">'#0066ff'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'a real data'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PAINT_POINTS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">G_paintings</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
                     <span class="n">c</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'G(z)'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s">'epoch = </span><span class="si">%</span><span class="s">d'</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="s">'D_accuracy = </span><span class="si">%.2</span><span class="s">f'</span> <span class="o">%</span> 
                     <span class="n">prob_real</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s">'D_loss = </span><span class="si">%.2</span><span class="s">f'</span> <span class="o">%</span> 
                     <span class="n">D_loss</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">draw</span><span class="p">();</span><span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>结果如下图：</p>

<p><img src="/img/gan_morvan.png" alt="" /></p>

<h2 id="4-このディオだ">4 このディオだ！</h2>

<p>WRYYYYYYYYYY！</p>

<h2 id="reference">Reference</h2>

<p>[1] <a href="https://www.msra.cn/zh-cn/news/features/gan-20170511">MSRA 到底什么是生成式对抗网络GAN？</a></p>

<p>[2] <a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/4-06-GAN/">莫烦 GAN with Pytorch 教程</a></p>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/Amoko/amoko.github.io">amoko.github.io</a> is maintained by <a href="https://github.com/Amoko">Amoko</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
